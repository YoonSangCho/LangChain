Abstract—Classification of multisensor signals is an im- portant problem in maintaining stable process operations, particularly in advancing predictive modeling for early de- tection of abnormal states. Self-supervised learning meth- ods, one of the representation learnings, have been widely studied. However, they have focused on using unlabeled data. In this study, we aim to address the challenge of effectively utilizing fully labeled data for modeling multi- sensor signals. We introduce supervised contrastive learn- ing (SCL) for the classification of multisensor signals. Our training framework involves a two-step process: SCL for en- coder pretraining with time-series data augmentations, and classifier training with the pretrained encoder. Our method exhibits superior performance, outperforming traditional supervised learning approaches by a substantial margin. Furthermore, we demonstrate the practical applicability of our approach for early prediction problems through experi- ments conducted with real-process data obtained from au- tomobile engine manufacturing. Our work offers a promis- ing method for multisensor signal analysis and early fault detection in manufacturing industries.
Index Terms—Automobile engine manufacturing, classi- fication, multisensor signals, supervised contrastive learn- ing (SCL), time-series data augmentation.

MULTISENSOR signal data are widely encountered in manufacturing systems [1]. Multisensor signal data are composed of time-series values obtained from multiple sensors attached to process equipment. Multiple sensors monitor aspects such as acceleration and vibration of the process states and machinery, producing a flow of signal data that can represent the features of both normal and abnormal states.

Classification of such multisensor signal data is an impor- tant and challenging problem in the manufacturing process. In particular, identifying abnormal signals plays a crucial role in maintaining stable process operations and preventing equipment failures. Traditional approaches, including rule-based systems, statistical methods, and signal-processing techniques, have ad- dressed this problem [2]. However, their implementation neces- sitates domain expertise and prior knowledge for identifying abnormal patterns in diverse sensor types. Moreover, these ap- proaches encounter challenges in effectively capturing complex patterns inherent in extensive quantities of multisensor signal data [3].

To this end, machine learning models trained on multisensor signals have been applied to accomplish various predictive tasks, including fault detection and diagnosis and machinery health monitoring [4], [5], [6], [7]. Nevertheless, they make an essential demand for manual feature extraction or dimensionality reduc- tion steps [3]. It is difficult to perform the joint optimization of the feature extraction method and the machine learning model, resulting in the inability of the extracted features to directly represent the abnormal status of equipment [8]. Consequently, exploring an effective method for representation learning of multisensor signal data becomes imperative.

Deep learning models incorporate representation learning and classification tasks in unified network architecture. Representa- tion learning involves training models to automatically discover and create meaningful representations or features from raw data. Long short-term memory and convolutional neural networks (CNNs) have become the primary methods with their outstand- ing predictive performance in time-series modeling [1], [9], [10]. Although the CNNs have been successfully applied to image and text data, they have also shown remarkable performance in time-series data [1]. They have applied for various predictive tasks, including fault detection and diagnosis [11], [12], [13], [14], machinery health monitoring [8], [10], and early detection [15], [16] in many industries.

In recent studies, the importance of representation learn- ing as a pretraining task has emerged in performing super- vised classification tasks [17], [18]. The main pretraining strat- egy is called self-supervised learning. Self-supervised learning does not require any labeled data but it creates self-defined pseudolabels as supervision; the positive samples are created from the data augmentation method, and the negative samples are other samples in the minibatch. Then, it performs repre- sentation learning by minimizing and maximizing the distance of positive and negative samples from the anchor, which is a target observation. The distance metric is often used as the inner product of the Euclidean distance between representation vec- tors of the examples [17]. It has shown successful performance in learning powerful representations, not only in the computer vision domain [17], [18] but also in time-series data or sensor signal data [19]. However, they have a risk of considering the samples of the same labels as negative samples. Self-supervised contrastive learning considers only one positive sample, which is augmented data from the anchor, and negative samples, com- prising all other data within a batch. Thus, within the negative samples, samples of the same labels with the anchor could be observed in a batch. It indicates that representations of the same label data are trained to push each other apart in the learned feature space.

In self-supervised learning of time-series data, augmentation techniques enable deep-learning models to learn various time- series patterns and increase their classification performance [20]. Many time-series data augmentation techniques are borrowed from image augmentations, such as random horizontal and ver- tical flipping. Two main methods of time-series augmentation are as follows: 1) the methods of magnitude domain include adding random noise under such names as jittering, scaling, and magnitude warping, and 2) the methods of time-domain include slicing and time-warping [20]. However, in the previous literature, time-series augmentation has not been considered for multisensor signals of manufacturing systems. Moreover, self-supervised learning methods for manufacturing systems have mainly focused on overcoming the lack of labeled data.

Modern large-scale manufacturing processes that collect real- time multisensor signals have created a need for advanced predictive models to represent the features of the sensor signals and identify abnormal states. In particular, in the early detection of abnormal signals, effective representation learning with data augmentations is required to guarantee predictive performance because, otherwise, abnormal symptoms may not become no- ticeable early enough to prevent an incident. It also necessitates data augmentations to enforce models to learn various scales and patterns of abnormal signals.
However, most existing approaches have largely focused on manual feature extraction methods of multisensor signals, revealing limitations for real-world applicability. Specifically, the traditional supervised learning approaches have overlooked data augmentation designed for time-series data in the context of multisensor signals in manufacturing contexts. While recent studies have made strides in leveraging self-supervised learn- ing for representation learning, they have focused on utilizing unlabeled data, neglecting the potential benefits of fully labeled data.

Our study addresses these limitations by introducing super- vised contrastive learning (SCL) that leverages data augmenta- tions and contrastive learning to maximize the utility of fully labeled data. Time-series augmentation [18] provides additional data of various scales and patterns, and contrastive learning based on labels increases the representation ability of class- wise features of multisensor signals. The SCL plays a role as the encoder pretraining strategy. It helps improve the model’s performance by initializing it with meaningful representations. Then, it is followed by classifier training by transfer learning (with a frozen pretrained encoder) or fine-tuning (with a trainable pretrained encoder) to build a final prediction model.

This study aims to improve the predictive performance in classification problems of multisensor signals using SCL. We address both single-label and multilabel classification problems in benchmark and case study scenarios, demonstrating the com- prehensive effectiveness of our method. In particular, in the case study, we apply SCL for early fault detection, which requires an advanced method to facilitate the identification of abnormal features for early prediction in manufacturing processes.
Although SCL was originally proposed for image data classi- fication, we believe this approach can also excel in the classifica- tion of multisensor signals. In this study, we propose using SCL to increase the performance of multisensor signals classification. The main contributions of this study can be summarized as follows.

1) We investigate the effectiveness of SCL leveraging the principles of data augmentations and contrastive learning framework in the classification of multisensor signals. To the best of our knowledge, this is the first attempt to apply the SCL strategy to multisensor signal data.

2) We adopt time-series augmentations to reflect the various signal patterns in encoder pretraining. In both supervised learning and SCL methods, this highlights the versatility and robustness of the approach across various signal representations.

3) We evaluate our method in both single-label and multilabel classification problems. Extensive experiments involving different model structures and augmentation types provide a comprehensive understanding and rationale of the proposed method’s effectiveness.

4) We demonstrate the applicability of our method for early fault detection in the real-world manufacturing process. We introduce data preprocessing methods for constructing input and output data for early prediction and apply our SCL to maximize the discernment of features of early alarms, which are particularly pertinent in automobile engine manufacturing scenarios.

The rest of this article is organized as follows. Section II introduces related work. Section III describes the details of the methodology. Sections IV and V describe the performance of our method under benchmark datasets and a case study, respectively. Finally, Section VI contains our concluding remarks.

II. RELATED WORK

A. Multisensor Signals Classification in Industries

Table I summarizes the comparisons of state-of-the-art train- ing methods and their applications. Deep learning models based on supervised learning are the most well-known approaches for multisensor signals classification. Qiao et al. [3] proposed a time-distributed spatiotemporal feature-learning method for machine health. Lee et al. [21] proposed a CNN structure in which a receptive field tailored to multisensor signals slides along the time axis to extract fault feature maps and perform fault detection. In addition, Yao et al. [22] attempted fault diag- nosis with CNN and a temporal attention mechanism to extract meaningful temporal parts from the sensor signals. Jing et al. [23] used CNNs for multiple fault classification by constructing two-dimensional multisensor data. Chen et al. [24] proposed deep neural networks (DNNs) based time-series modeling for equipment reliability analysis. Zhao et al. [11] developed CNN variants that use soft thresholding to improve feature learning capability from noisy signal patterns and diagnosis accuracy. Liu et al. [13] developed a diagnosis framework based on the characteristics of industrial vibration signals. They added a dis- locate layer in the CNN model to extract the relationship between signals with different intervals in periodic mechanical signals. In the healthcare industry, deep learning models have been widely applied to prediction systems of patient outcomes [25]. Khan et al. [26] proposed a modified CNN to predict heart disease using patients’ blood pressure and electrocardiogram sensor data obtained from wearable devices. Ali et al. [27] introduced a smart healthcare monitoring system for heart disease prediction using ensemble deep learning based on multiple physiological sensor data. However, it is worth noting that the majority of studies have not attempted representation learning through data augmentation techniques in modern manufacturing processes that necessitate learning from various patterns of sensor data (see Table I).

Gupta et al. [16] applied zero-shot learning with a semantic information-based early classification approach using multivari- ate time series data for early classification of an unseen fault. Zhou et al. [12] applied a few-shot learning with a Siamese CNN to alleviate the overfitting problem and enhance anomaly detection accuracy in industrial cyber-physical systems. These approaches serve as alternatives that aim to address the chal- lenges associated with limited labeled data.
The two-stage approach is also a popular strategy for mul- tisensor signals classification. It consists of an unsupervised pretraining stage to extract compressed features and a supervised fine-tuning stage for classifier training. Xie et al. [14] used a multisignals-to-RGB-image conversion method based on prin- cipal component analysis to fuse multisensor signal data in 3-D images and applied it to CNN. Chen et al. [28] proposed sparse autoencoder-based feature extraction of multiple accelerometer sensors and performed classification with a deep belief network to diagnose faults. Luo et al. [15] also constructed sparse autoen- coders and DNNs using vibration signals for the early detection of faults in machine tools.

As another two-stage strategy, self-supervised learning ap- proaches for sensor signals have been attracting attention as a means to overcome the lack of labeled data. Zhang et al. [29] proposed a self-supervised contrastive learning method using vibration signals for fault diagnosis. They applied wavelet trans- forms to extract features from original signals and multi-instance contrastive. Von et al. [30] proposed self-supervised learning of disentangled-variational-autoencoder with a temporal CNN for anomaly detection. Senanayaka et al. [31] proposed an online fault diagnosis framework in electric powertrains without using labeled sensor signal data. The self-supervised learning of CNN was included in their framework. Zhang et al. [32] proposed a self-supervised joint learning fault diagnosis method based on three-channel vibration images to reduce the dependence on labeled data.

Although these approaches present promising solutions to overcome the need for labeled data, our focus remains on enhancing classification performance with fully labeled data. In addition, the relevant studies mentioned above have not considered data augmentation techniques for representation learning. We, thus, propose SCL with time-series augmentation for representation learning of multisensor signals that can use label information effectively. B. Supervised Contrastive Learning
SCL was first proposed to improve image data classification performance, but it is the most relevant method for our study. Khosla et al. [18] extended the self-supervised batch contrastive approach to a fully supervised setting to leverage label information effectively. They analyzed the effectiveness of supervised contrastive loss (SupConLoss) that pulls together the features of the same classes (positive samples) in embedding space while simultaneously pushing apart features of different classes (negative samples). As a result, the SCL achieved a top-1 accuracy of 81.4% on the ImageNet dataset using ResNet-200 and consistently outperformed cross-entropy on other datasets and two residual networks (ResNet) variants.

In the field of natural language processing, the state-of-the-art classification models also follow two-stage modeling: pretrain- ing a large language model on an auxiliary task and using cross-entropy loss to fine-tune the model on a task-specific labeled dataset [33]. However, Gunel et al. [33] noted that cross-entropy loss has several shortcomings that can lead to suboptimal generalization and instability. They combined cross-entropy and their SCL loss to improve over a strong Roberta- Large baseline [34]. The point is that they used text data to apply an SCL objective instead of using it for pretraining to fine-tune the pretrained language model. They verified the performance of their method with the general language understanding evaluation benchmark datasets and few-shot learning settings without data augmentations. Existing studies have shown the effect of using SCL for image and text data, but its use has not yet been considered in multisensor signal data (see Table I). In this study, we exploit the effectiveness of SCL in multisensor signals classification.


